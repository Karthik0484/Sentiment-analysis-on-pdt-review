"""
Sentiment Analysis App
User Interface for Product Review Sentiment Prediction
Optimized for Performance (Caching & Latency Reduction)
"""

import streamlit as st
import pandas as pd
import numpy as np
import pickle
import os
import re
import nltk
import matplotlib.pyplot as plt
import seaborn as sns

import time
import io
from datetime import datetime
from reportlab.lib import colors
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.units import inch
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, Image, PageBreak
from reportlab.pdfgen import canvas

import speech_recognition as sr
from pydub import AudioSegment
import static_ffmpeg

# ============================================================================
# PERFORMANCE OPTIMIZATION: 1. SETUP & CONFIGURATION
# ============================================================================
st.set_page_config(
    page_title="Sentiment Analysis System",
    page_icon="ü§ñ",
    layout="centered"
)

# Initialize static-ffmpeg to allow MP3 processing without manual OS install
try:
    static_ffmpeg.add_paths()
except Exception:
    pass

# ============================================================================
# PERFORMANCE OPTIMIZATION: 2. CACHED RESOURCE LOADING
# ============================================================================

# Define paths
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(BASE_DIR)
MODELS_DIR = os.path.join(PROJECT_ROOT, 'models')

# ============================================================================
# PERFORMANCE OPTIMIZATION: PDF REPORT GENERATION (Refined Layout)
# ============================================================================

class PDFReport:
    def __init__(self, product_name):
        self.product_name = product_name if product_name else "Not Specified"

    def add_page_number(self, canvas, doc):
        """Add footer with page number and system info"""
        canvas.saveState()
        canvas.setFont('Helvetica-Oblique', 8)
        canvas.setStrokeColor(colors.lightgrey)
        canvas.line(1 * inch, 0.75 * inch, 7.5 * inch, 0.75 * inch)
        
        footer_text = "Generated by Sentiment Analysis System | Page %d" % doc.page
        canvas.drawCentredString(A4[0]/2.0, 0.5 * inch, footer_text)
        canvas.restoreState()

def generate_pdf_report(df, product_name, counts, pie_fig, bar_fig):
    """
    Generate a professional PDF report using ReportLab Platypus.
    """
    buffer = io.BytesIO()
    doc = SimpleDocTemplate(
        buffer, 
        pagesize=A4,
        rightMargin=72, leftMargin=72,
        topMargin=72, bottomMargin=72
    )
    
    styles = getSampleStyleSheet()
    
    # Custom Styles
    title_style = ParagraphStyle(
        'MainTitle',
        parent=styles['Heading1'],
        fontSize=28,
        alignment=1, # Center
        spaceAfter=30,
        fontName='Helvetica-Bold',
        textColor=colors.HexColor("#1A1A1A")
    )
    
    section_style = ParagraphStyle(
        'SectionHeader',
        parent=styles['Heading2'],
        fontSize=20,
        fontName='Helvetica-Bold',
        spaceBefore=20,
        spaceAfter=15,
        textColor=colors.HexColor("#2C3E50"),
        borderPadding=(0, 0, 5, 0),
        borderWidth=0,
        borderStyle=None
    )
    
    bullet_style = ParagraphStyle(
        'BulletPoint',
        parent=styles['Normal'],
        fontSize=12,
        leading=18,
        leftIndent=20,
        bulletIndent=10,
        spaceBefore=8
    )

    meta_style = ParagraphStyle(
        'Metadata',
        parent=styles['Normal'],
        fontSize=12,
        leading=16,
        spaceAfter=6
    )

    story = []
    
    # 1. Main Title
    story.append(Paragraph("Sentiment Analysis Report", title_style))
    
    # Draw a line below the title
    story.append(Spacer(1, 5))
    
    # 2. Metadata Section
    curr_time = datetime.now().strftime('%B %d, %Y | %H:%M:%S')
    story.append(Paragraph(f"<b>Product Name:</b> {product_name if product_name else 'Not Specified'}", meta_style))
    story.append(Paragraph(f"<b>Analysis Date:</b> {curr_time}", meta_style))
    story.append(Paragraph(f"<b>Total Reviews Processed:</b> {len(df)}", meta_style))
    story.append(Spacer(1, 15))
    
    # 3. Executive Summary
    story.append(Paragraph("Executive Summary", section_style))
    total = len(df)
    for cat in ['positive', 'neutral', 'negative']:
        count = counts.get(cat, 0)
        perc = (count / total * 100) if total > 0 else 0
        story.append(Paragraph(f"&bull; <b>{cat.capitalize()}:</b> {count} reviews ({perc:.1f}%)", bullet_style))
    story.append(Spacer(1, 25))
    
    # 4. Visual Insights
    story.append(Paragraph("Visual Insights", section_style))
    
    # Prepare chart images
    pie_buf = io.BytesIO()
    pie_fig.savefig(pie_buf, format='png', bbox_inches='tight', dpi=200)
    pie_buf.seek(0)
    
    bar_buf = io.BytesIO()
    bar_fig.savefig(bar_buf, format='png', bbox_inches='tight', dpi=200)
    bar_buf.seek(0)
    
    # Reduced slightly for better fit within margins
    img_pie = Image(pie_buf, width=3.1*inch, height=3.1*inch)
    img_bar = Image(bar_buf, width=3.1*inch, height=3.1*inch)
    
    chart_table = Table([[img_pie, img_bar]], colWidths=[3.25*inch, 3.25*inch])
    chart_table.setStyle(TableStyle([
        ('ALIGN', (0,0), (-1,-1), 'CENTER'),
        ('VALIGN', (0,0), (-1,-1), 'MIDDLE'),
        ('LEFTPADDING', (0,0), (-1,-1), 0),
        ('RIGHTPADDING', (0,0), (-1,-1), 0),
    ]))
    story.append(chart_table)
    story.append(Spacer(1, 25))
    
    # 5. Detailed Data Table
    story.append(PageBreak())
    story.append(Paragraph("Detailed Data Table", section_style))
    
    data = [["#", "Review Text", "Sentiment"]]
    for i, (_, row) in enumerate(df.iterrows()):
        txt = str(row['review_text'])
        sent = str(row['predicted_sentiment']).capitalize()
        data.append([str(i+1), Paragraph(txt, styles['Normal']), sent])
    
    # Professional Table Styling
    t = Table(data, colWidths=[0.5*inch, 5.0*inch, 1.25*inch], repeatRows=1)
    t.setStyle(TableStyle([
        # Header Styling
        ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor("#34495E")),
        ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
        ('FONTSIZE', (0, 0), (-1, 0), 11),
        
        # Row Styling
        ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),
        ('FONTSIZE', (0, 1), (-1, -1), 10),
        ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor("#F2F4F4")]),
        
        # Alignment & Padding
        ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
        ('ALIGN', (0, 0), (0, -1), 'CENTER'),
        ('ALIGN', (-1, 0), (-1, -1), 'CENTER'),
        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
        ('TOPPADDING', (0, 0), (-1, -1), 8),
        ('BOTTOMPADDING', (0, 0), (-1, -1), 8),
        ('LEFTPADDING', (0, 0), (-1, -1), 8),
        ('RIGHTPADDING', (0, 0), (-1, -1), 8),
        
        # Grid
        ('LINEBELOW', (0, 0), (-1, 0), 2, colors.HexColor("#2C3E50")),
        ('GRID', (0, 1), (-1, -1), 0.5, colors.lightgrey),
    ]))
    story.append(t)
    
    # Build PDF
    reporter = PDFReport(product_name)
    doc.build(story, onFirstPage=reporter.add_page_number, onLaterPages=reporter.add_page_number)
    
    pdf_val = buffer.getvalue()
    buffer.close()
    return pdf_val

# ============================================================================
# AUDIO PROCESSING LOGIC
# ============================================================================

# ============================================================================
# PRODUCTION-READY AUDIO PROCESSING (CHUNKED & NORMALIZED)
# ============================================================================

def normalize_audio(audio_file):
    """
    Normalize audio to Mono, 16000Hz, 16-bit PCM WAV for better OCR.
    Requirement: Part 1
    """
    try:
        audio_file.seek(0)
        audio = AudioSegment.from_file(audio_file)
        
        # 1. Convert to Mono
        audio = audio.set_channels(1)
        # 2. Convert frame rate to 16000 Hz
        audio = audio.set_frame_rate(16000)
        # 3. Ensure 16-bit (2 bytes) PCM
        audio = audio.set_sample_width(2)
        
        # In-memory export
        normalized_io = io.BytesIO()
        audio.export(normalized_io, format="wav")
        normalized_io.seek(0)
        return normalized_io
    except Exception as e:
        st.error(f"Normalization failed: {str(e)}")
        return None

def split_audio_into_chunks(audio_file, chunk_length_ms=15000):
    """
    Split audio into 15-second chunks in-memory.
    Requirement: Part 3
    """
    try:
        audio_file.seek(0)
        audio = AudioSegment.from_file(audio_file)
        
        chunks = []
        for i in range(0, len(audio), chunk_length_ms):
            chunk = audio[i:i + chunk_length_ms]
            chunks.append(chunk)
        
        return chunks
    except Exception as e:
        st.error(f"Chunking failed: {str(e)}")
        return []

def transcribe_chunks(chunks):
    """
    Transcribe audio chunks with recognizer tuning and error handling.
    Requirement: Part 2 & 3
    """
    recognizer = sr.Recognizer()
    # Part 2: Recognizer Tuning
    recognizer.dynamic_energy_threshold = True
    recognizer.energy_threshold = 300 
    
    full_transcript = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    for idx, chunk in enumerate(chunks):
        status_text.text(f"Processing part {idx+1} of {len(chunks)}...")
        
        # Convert chunk to WAV in-memory
        chunk_buffer = io.BytesIO()
        chunk.export(chunk_buffer, format="wav")
        chunk_buffer.seek(0)
        
        try:
            with sr.AudioFile(chunk_buffer) as source:
                # Part 2: Ambient Noise Adjustment
                recognizer.adjust_for_ambient_noise(source, duration=0.4)
                # Part 2: Use record() for chunks
                audio_data = recognizer.record(source)
                
                text = recognizer.recognize_google(audio_data)
                if text:
                    # Part 6: Cleanup - Basic cleaning during merge
                    text = text.strip()
                    full_transcript.append(text)
        except sr.UnknownValueError:
            continue
        except sr.RequestError:
            st.error("API Limit reached or Internet lost.")
            break
        except Exception:
            continue
        
        progress_bar.progress((idx + 1) / len(chunks))
    
    status_text.empty()
    progress_bar.empty()
    
    combined = " ".join(full_transcript)
    
    # Part 6: Transcript Cleanup
    # Remove extra spaces and normalize
    combined = re.sub(r'\s+', ' ', combined).strip()
    
    return combined

def audio_to_text(audio_file):
    """
    Orchestrator for improved audio recognition.
    Requirement: Fixed long-audio truncation & Improved accuracy.
    """
    # Part 1: Normalization
    with st.spinner("üéß Normalizing audio (16kHz, Mono)..."):
        normalized_audio_io = normalize_audio(audio_file)
    
    if not normalized_audio_io:
        return "ERROR: Normalization failed."
    
    # Part 3: Chunking (15s)
    with st.spinner("‚úÇÔ∏è Chunking audio (15s)..."):
        chunks = split_audio_into_chunks(normalized_audio_io)
    
    if not chunks:
        return "ERROR: Could not split audio."
    
    # Part 3: Transcribing
    with st.spinner("üéôÔ∏è Transcribing with tuned recognizer..."):
        transcript = transcribe_chunks(chunks)
        
    if not transcript:
        return "ERROR: No text detected."
        
    return transcript

# ============================================================================
# SEGMENTATION & BATCH ANALYSIS LOGIC
# ============================================================================

def split_reviews(transcript):
    """
    Regex-based segmentation for robust splitting.
    Requirement: Part 4
    """
    if not transcript or not transcript.strip():
        return []
    
    # Convert to lowercase
    transcript_lower = transcript.lower()
    
    # Use regex splitting for 'next review' (Part 4)
    # This handles various spacing and ensures robust matching
    segments = re.split(r"next review", transcript_lower)
    
    cleaned_segments = []
    for seg in segments:
        # Part 6: Cleanup whitespace and punctuation
        seg = seg.strip()
        seg = re.sub(r'^[^\w\s]+|[^\w\s]+$', '', seg)
        if seg:
            cleaned_segments.append(seg)
            
    # Fallback (Part 4): If no splits occurred, return entire transcript
    return cleaned_segments if cleaned_segments else [transcript.strip()]

def analyze_reviews_batch(segments, vectorizer, model):
    """
    Analyze a list of review segments in batch for efficiency.
    Requirement 4 & 7
    """
    if not segments:
        return []
    
    # 1. Preprocess each segment using existing logic
    processed_segments = [preprocess_text(seg) for seg in segments]
    
    # 2. Transform using existing TF-IDF vectorizer (Requirement 7 - Avoid loops)
    features = vectorizer.transform(processed_segments)
    
    # 3. Predict sentiment using existing model
    predictions = model.predict(features)
    
    # 4. Compute confidence score using predict_proba() (Requirement 4)
    probabilities = model.predict_proba(features)
    
    results = []
    for i, seg in enumerate(segments):
        pred_label = predictions[i]
        prob_dist = probabilities[i]
        
        # Find index of predicted label to get confidence
        pred_idx = np.where(model.classes_ == pred_label)[0][0]
        confidence = prob_dist[pred_idx]
        
        results.append({
            'text': seg,
            'sentiment': pred_label,
            'confidence': confidence
        })
        
    return results

def display_sentiment_summary(df_results, title="Analysis Summary"):
    """
    Shared visualization component for summarizing multiple predictions.
    Requirement 6 & 9
    """
    counts = df_results['sentiment'].value_counts()
    for cat in ['positive', 'neutral', 'negative']:
        if cat not in counts: counts[cat] = 0
            
    st.markdown(f"### {title}")
    m1, m2, m3 = st.columns(3)
    m1.metric("üòä Positive", counts['positive'])
    m2.metric("üòê Neutral", counts['neutral'])
    m3.metric("üòî Negative", counts['negative'])
    
    # Visualizations
    dist_data = counts.reindex(['positive', 'neutral', 'negative']).fillna(0)
    col_v1, col_v2 = st.columns(2)
    
    with col_v1:
        fig_pie, ax_pie = plt.subplots(figsize=(6, 6))
        ax_pie.pie(dist_data, labels=[c.capitalize() for c in dist_data.index], autopct='%1.1f%%', startangle=140, colors=['#28a745', '#ffc107', '#dc3545'])
        ax_pie.set_title("Sentiment Proportions")
        st.pyplot(fig_pie)
        
    with col_v2:
        fig_bar, ax_bar = plt.subplots(figsize=(6, 6))
        dist_data.plot(kind='bar', color=['#28a745', '#ffc107', '#dc3545'], ax=ax_bar)
        ax_bar.set_title("Sentiment Comparison")
        ax_bar.set_ylabel("Review Count")
        ax_bar.set_xticklabels([c.capitalize() for c in dist_data.index], rotation=0)
        st.pyplot(fig_bar)
    
    return fig_pie, fig_bar, counts

@st.cache_resource(show_spinner=False)
def initialize_nltk():
    """
    Optimize NLTK usage by downloading resources only once
    and returning necessary objects to avoid re-initialization.
    """
    resources = [
        ('punkt', 'tokenizers/punkt'),
        ('punkt_tab', 'tokenizers/punkt_tab'),
        ('stopwords', 'corpora/stopwords'),
        ('wordnet', 'corpora/wordnet'),
        ('omw-1.4', 'corpora/omw-1.4')
    ]
    
    for resource, path in resources:
        try:
            nltk.data.find(path)
        except LookupError:
            nltk.download(resource, quiet=True)
    
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize
    from nltk.stem import WordNetLemmatizer
    
    stop_words = set(stopwords.words('english'))
    # REQUIREMENT: Negation Handling Improvement (Part 5)
    # Ensure these words are NOT removed as they are critical for sentiment
    negations = {'not', 'no', 'never', 'neither', 'nor', 'none', "n't"}
    stop_words = stop_words - negations
    
    lemmatizer = WordNetLemmatizer()
    
    return word_tokenize, stop_words, lemmatizer

# Initialize NLTK resources once
word_tokenize, stop_words, lemmatizer = initialize_nltk()

@st.cache_resource(show_spinner=False)
def load_models():
    """
    Load ML models and vectorizers only once and cache them in memory.
    This prevents reloading large files on every interaction.
    """
    try:
        # Load Vectorizer
        vectorizer_path = os.path.join(MODELS_DIR, 'tfidf_vectorizer.pkl')
        with open(vectorizer_path, 'rb') as f:
            vectorizer = pickle.load(f)
            
        # Load Model
        model_path = os.path.join(MODELS_DIR, 'sentiment_classifier_nb.pkl')
        with open(model_path, 'rb') as f:
            model = pickle.load(f)
            
        return vectorizer, model
    except FileNotFoundError:
        return None, None

# Load models with a spinner only on the first run
with st.spinner("üöÄ Booting up AI Engine..."):
    vectorizer, model = load_models()

if vectorizer is None or model is None:
    st.error("‚ùå Model files not found! Please ensure Step 3 and Step 4 are completed.")
    st.stop()

# ============================================================================
# PERFORMANCE OPTIMIZATION: 3. CACHED PREPROCESSING
# ============================================================================

@st.cache_data(show_spinner=False)
def preprocess_text(text):
    """
    Cache the preprocessing results.
    """
    if not isinstance(text, str) or not text.strip():
        return ""
        
    # 1. Lowercasing
    text = text.lower()
    
    # 2. Remove punctuation, special characters, and numbers
    text = re.sub(r'[^\w\s]|[\d]', '', text)
    
    # 3. Tokenization
    tokens = word_tokenize(text)
    
    # 4. Stopwords Removal & Lemmatization
    tokens = [lemmatizer.lemmatize(t) for t in tokens if t not in stop_words]
    
    return ' '.join(tokens)

# ============================================================================
# USER INTERFACE - SHARED COMPONENTS
# ============================================================================

# Header
st.title("üõçÔ∏è Sentiment Analysis System")
st.markdown("Analyze product reviews and detect sentiment instantly using AI.")
st.markdown("---")

# Shared Product Information Section
with st.container():
    st.subheader("üì¶ Product Information")
    col1, col2 = st.columns([2, 1])

    with col1:
        product_name = st.text_input(
            "Product Name (Optional)",
            placeholder="e.g., Samsung Galaxy M14",
            help="This name will appear in generated reports."
        )

    with col2:
        rating = st.selectbox(
            "User Rating (Optional)",
            options=[0, 1, 2, 3, 4, 5],
            index=5,
            format_func=lambda x: f"{x} Stars" if x > 0 else "Not Rated",
            help="Used for comparison with AI predictions."
        )

st.markdown("---")

# Analysis Mode Selector
analysis_mode = st.radio(
    "Select Analysis Mode",
    options=["Single Review", "Bulk Review Upload"],
    horizontal=True,
    help="Choose between individual review analysis or batch CSV processing."
)

st.markdown("---")

# ============================================================================
# SINGLE REVIEW MODE
# ============================================================================
if analysis_mode == "Single Review":
    review_type = st.radio(
        "Review Format",
        options=["Text Review", "Audio Review", "Video (Coming Soon)"],
        index=0,
        horizontal=True
    )

    review_text = ""
    audio_processed_text = None

    if review_type == "Audio Review":
        st.info("üéôÔ∏è **Instruction:** If your audio contains multiple reviews, please say **'NEXT REVIEW'** clearly between each review.")
        uploaded_audio = st.file_uploader("Upload Audio File", type=["wav", "mp3"], help="Upload a clear .wav or .mp3 file.")
        
        if uploaded_audio:
            st.audio(uploaded_audio)
            
            if st.button("üé§ Transcribe & Analyze", type="primary", use_container_width=True):
                # Full orchestrator call (includes chunking and transcription)
                audio_processed_text = audio_to_text(uploaded_audio)
                
                if audio_processed_text.startswith("ERROR:"):
                    st.error(audio_processed_text)
                    audio_processed_text = None
                else:
                    st.success("‚úÖ Transcription Complete!")
                    with st.expander("üìù View Full Transcript"):
                        st.write(audio_processed_text)
                    review_text = audio_processed_text

    elif review_type == "Text Review":
        review_text = st.text_area(
            "Review Content",
            height=150,
            placeholder="Type your detailed product review here..."
        )
    else:
        st.info("üîú This feature is currently in development. Please use Text or Audio mode.")
        review_text = ""

    # Use a flag for prediction to avoid duplicating prediction logic
    analyze_btn = False
    if review_type == "Text Review":
        analyze_btn = st.button("üîç Analyze Sentiment", type="primary", use_container_width=True)
    elif review_type == "Audio Review" and audio_processed_text:
        # If successfully transcribed, we auto-trigger analysis or use the button state
        analyze_btn = True

    if analyze_btn:
        if not review_text or not review_text.strip():
            if review_type == "Text Review":
                st.warning("‚ö†Ô∏è Please provide some review text.")
            # If Audio and buttons were pressed but transcript was empty, already handled in audio_to_text
        else:
            with st.spinner("üß† Analyzing segmented reviews..."):
                if review_type == "Audio Review":
                    # KEY FEATURE: Segmentation Logic (Requirement 1-9)
                    segments = split_reviews(review_text)
                    
                    if not segments:
                        st.error("‚ùå Transcript is empty. Could not detect any reviews.")
                    else:
                        st.info(f"üìã Detected {len(segments)} review(s) in audio.")
                        
                        # Batch Analyze (Requirement 7)
                        results = analyze_reviews_batch(segments, vectorizer, model)
                        
                        # Display Individual Results (Requirement 5)
                        for i, res in enumerate(results):
                            sentiment_map = {
                                'positive': {'color': 'green', 'emoji': 'üòÉ'},
                                'neutral': {'color': 'orange', 'emoji': 'üòê'},
                                'negative': {'color': 'red', 'emoji': 'üòî'}
                            }
                            result_style = sentiment_map.get(res['sentiment'], {'color': 'gray', 'emoji': '‚ùì'})
                            
                            with st.expander(f"Review {i+1}: {res['sentiment'].capitalize()}", expanded=(len(segments) == 1)):
                                st.markdown(f"**Text:** {res['text']}")
                                st.markdown(
                                    f"""
                                    <div style="padding: 10px; border-radius: 5px; border-left: 5px solid {result_style['color']}; background-color: #f9f9f9;">
                                        <strong>Sentiment:</strong> {result_style['emoji']} {res['sentiment'].capitalize()} <br>
                                        <strong>Confidence:</strong> {res['confidence']*100:.2f}%
                                    </div>
                                    """,
                                    unsafe_allow_html=True
                                )
                        
                        # Display Summary if more than 1 review or always for consistency (Requirement 6 & 9)
                        if len(results) >= 1:
                            st.markdown("---")
                            df_results = pd.DataFrame(results)
                            
                            # Use helper for charts and counts
                            fig_pie, fig_bar, counts = display_sentiment_summary(df_results, title="Audio Review Analytics")
                            
                            # Table & Export (Consistency with Bulk mode - Requirement 9)
                            st.markdown("---")
                            st.subheader("üìù Segmented Data Table")
                            # Format for display
                            df_display = df_results[['text', 'sentiment', 'confidence']].copy()
                            df_display['confidence'] = df_display['confidence'].apply(lambda x: f"{x*100:.2f}%")
                            st.dataframe(df_display, use_container_width=True)
                            
                            # Export Buttons
                            c1, c2 = st.columns(2)
                            
                            with c1:
                                csv_export = df_results[['text', 'sentiment']].to_csv(index=False).encode('utf-8')
                                st.download_button("üì• Download Results (CSV)", csv_export, "audio_results.csv", "text/csv", key="audio_csv", use_container_width=True)
                            
                            with c2:
                                with st.spinner("Generating PDF Report..."):
                                    # Alignment with existing PDF logic: rename columns for report
                                    df_for_report = df_results.copy()
                                    df_for_report.rename(columns={'text': 'review_text', 'sentiment': 'predicted_sentiment'}, inplace=True)
                                    
                                    pdf_data = generate_pdf_report(df_for_report, product_name if product_name else "Audio Review", counts, fig_pie, fig_bar)
                                    
                                    st.download_button(
                                        label="üìÑ Download Full Report (PDF)",
                                        data=bytes(pdf_data),
                                        file_name=f"audio_sentiment_report.pdf",
                                        mime="application/pdf",
                                        key="audio_pdf",
                                        use_container_width=True
                                    )
                
                else:
                    # Original Single Text Review Logic
                    processed_text = preprocess_text(review_text)
                    features = vectorizer.transform([processed_text])
                    probabilities = model.predict_proba(features)[0]
                    
                    prediction_idx = np.argmax(probabilities)
                    prediction_label = model.classes_[prediction_idx]
                    confidence = probabilities[prediction_idx] * 100
                    
                    sentiment_map = {
                        'positive': {'color': 'green', 'emoji': 'üòÉ'},
                        'neutral': {'color': 'orange', 'emoji': 'üòê'},
                        'negative': {'color': 'red', 'emoji': 'üòî'}
                    }
                    
                    result = sentiment_map.get(prediction_label, {'color': 'gray', 'emoji': '‚ùì'})
                    
                    # Display Results
                    st.markdown(f"### Results for: {product_name if product_name else 'Unnamed Product'}")
                    
                    st.markdown(
                        f"""
                        <div style="background-color: #f0f2f6; padding: 20px; border-radius: 10px; border-left: 5px solid {result['color']}; text-align: center;">
                            <h2 style="color: {result['color']}; margin:0;">{result['emoji']} {prediction_label.capitalize()}</h2>
                            <p style="margin:5px; font-size: 18px;">Confidence: <strong>{confidence:.2f}%</strong></p>
                        </div>
                        """,
                        unsafe_allow_html=True
                    )
                    
                    if rating > 0:
                        is_match = (
                            (rating >= 4 and prediction_label == 'positive') or 
                            (rating == 3 and prediction_label == 'neutral') or 
                            (rating <= 2 and prediction_label == 'negative')
                        )
                        if is_match:
                            st.success("‚úÖ Prediction alignment: Matches user star rating!")
                        else:
                            st.info("‚ÑπÔ∏è Note: Detected sentiment differs from star rating.")

                    with st.expander("üìä Probability Breakdown"):
                        probs_df = pd.DataFrame({
                            'Sentiment': [c.capitalize() for c in model.classes_],
                            'Probability': probabilities
                        })
                        st.bar_chart(probs_df.set_index('Sentiment'))

# ============================================================================
# BULK REVIEW MODE
# ============================================================================
else:
    st.header("üìÇ Bulk Review Upload")
    st.info("üí° **Instructions:** Ensure your CSV contains a column named **'review_text'**.")
    
    # Sample Template
    sample_data = pd.DataFrame({"review_text": ["Great product!", "Bad quality.", "It's average.", "Cool but expensive.", "Fast delivery!"]})
    sample_csv = sample_data.to_csv(index=False).encode('utf-8')
    st.download_button("üì• Download Sample CSV", sample_csv, "sample_bulk_reviews.csv", "text/csv")
    
    st.markdown("---")
    uploaded_file = st.file_uploader("Upload CSV File", type=["csv"])
    
    if uploaded_file:
        try:
            df_bulk = pd.read_csv(uploaded_file)
            if "review_text" not in df_bulk.columns:
                st.error("‚ùå Column 'review_text' missing.")
            else:
                st.write(f"‚úÖ Found {len(df_bulk)} reviews to process.")
                
                if st.button("üöÄ Analyze All Reviews", type="primary", use_container_width=True):
                    start_time = time.time()
                    
                    with st.spinner("Analyzing bulk reviews..."):
                        # PERFORMANCE OPTIMIZATION: 
                        # 1. Preprocessing is cached per text
                        df_bulk['processed_text'] = df_bulk['review_text'].apply(preprocess_text)
                        
                        # 2. Vectorized Feature Extraction (Single batch call)
                        features = vectorizer.transform(df_bulk['processed_text'])
                        
                        # 3. Vectorized Prediction (Single batch call)
                        predictions = model.predict(features)
                        df_bulk['sentiment'] = predictions  # Renamed for consistency with helper
                        df_bulk['predicted_sentiment'] = predictions # Keep original for compatibility if needed below
                        
                    duration = time.time() - start_time
                    st.success(f"‚ö° Extraction & Analysis completed in {duration:.2f} seconds!")
                    
                    # Dashboard Summary (Using helper for consistency - Requirement 9)
                    if product_name:
                        summary_title = f"Summary for: {product_name}"
                    else:
                        summary_title = "Bulk Analysis Summary"
                    
                    fig_pie, fig_bar, counts = display_sentiment_summary(df_bulk, title=summary_title)
                    
                    # Table & Export
                    st.markdown("---")
                    st.subheader("üìù Processed Data Table")
                    st.dataframe(df_bulk[['review_text', 'predicted_sentiment']], use_container_width=True)
                    
                    # Export Buttons
                    c1, c2 = st.columns(2)
                    
                    with c1:
                        csv_export = df_bulk[['review_text', 'predicted_sentiment']].to_csv(index=False).encode('utf-8')
                        st.download_button("üì• Download Results (CSV)", csv_export, "bulk_results.csv", "text/csv", use_container_width=True)
                    
                    with c2:
                        with st.spinner("Generating PDF Report..."):
                            pdf_data = generate_pdf_report(df_bulk, product_name, counts, fig_pie, fig_bar)
                            
                            # Clean filename
                            clean_name = product_name.replace(" ", "_").lower() if product_name else "bulk_reviews"
                            
                            st.download_button(
                                label="üìÑ Download Full Report (PDF)",
                                data=bytes(pdf_data),
                                file_name=f"sentiment_report_{clean_name}.pdf",
                                mime="application/pdf",
                                use_container_width=True
                            )
                    
        except Exception as e:
            st.error(f"‚ùå Error: {str(e)}")

st.markdown("---")
st.caption("Sentiment Analysis System | Performance Optimized v2.0")
